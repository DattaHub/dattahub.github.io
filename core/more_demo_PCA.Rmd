---
title: "More on PCA"
author: "Jyotishka Datta"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
  css: mystyle.css
lib_dir: libs
nature:
  highlightStyle: github
highlightLines: true
countIncrementalSlides: false
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
options(
  htmltools.dir.version = FALSE, # for blogdown
  width=80
)

# library(emo)
htmltools::tagList(rmarkdown::html_dependency_font_awesome())
crime<-read.table("~/GitHub/DattaHub.github.io/data-analytics/data/city_crime.txt")
```

## Source/Reading:

-  These slides have `R` codes and commentary and in addition the following sections are heavily recommended: 

>  Chapter 8.1 - 8.4 from Zelterman's book.


>  Chapter 3.1 - 3.12 from Everitt's book. 


---
## Example: Pluto (Zelterman)

-  In 2006, Pluto was demoted from the status of a planet and is now considered one of the many objects orbitting the sun at a similar distance. 

- KBO: Kuiper belt objects: more than a thousand known objects, and there are estimates of many tens of thousands more yet to be discovered.

```{r, echo = F, out.height=300, out.width=600}
knitr::include_graphics("images/Kuiperbelt.jpg")
```



---
## Example: Pluto 

-  Data from the largest KBO's below. 
-  `Albedo`: light reflected rather than absorbed. 
-  `Absolute magnitude`: Apparent brightness, corrected for distance in log-scale. 
-   Is Pluto similar to the other KBOs?

```{r, echo = F, out.height=300, out.width=600}
knitr::include_graphics("images/pluto.png")
```


---
## Kuiper Belt Object 

```{r}

KBO <- read.csv("kuiper_belt_objects.csv")
str(KBO)
Kuiper <- KBO[,-c(1,2)]
colnames(Kuiper) <- c("mag","albedo","diameter","axis","year")
head(Kuiper, n = 3)
```

---
## Principal Components

-  Perform PCA on the `Kuiper` dataset. 

```{r}
KuiPC <- princomp(Kuiper)
summary(KuiPC)
```

- From this,we see 99.8% of the variability is explained in the first principal component.
On the surface, this appears to be a remarkable reduction in the dimensionality
of the problem.

---
## Loadings

-  The first PC is simply the diameter variable. Why is that? 

```{r}
KuiPC$loadings
```

---
## Look at the variances 

-  This happens because the variances (or the standard deviations) of the variables are widely different.

-  The `diameter` variable has the largest variability, by far. Hence it dominates the first PC. 

```{r}
sapply(Kuiper, sd)
```


---
## PCA on Correlation matrix

-  A better approach, then, is to record all of these values on the same scale. The principal components should be obtained from the correlation matrix in most cases.

-   use the `cor=TRUE` option as in this dialog:


```{r}
KuiPCc <- princomp(Kuiper, cor = TRUE)

summary(KuiPCc)
```

-  The first two principal components account for almost 90% of the variability.

---
## New Loadings

```{r}
KuiPCc$loadings
```

The first principal component of the Kuiper objects is approximately
$$
{\rm Magnitude + Year~of~discovery - Albedo - Diameter}
$$

and the second component is almost entirely the axis.

---
## Biplot

```{r, fig.asp = 0.9, fig.align='center'}
biplot(KuiPCc, col = c(2,3), cex = c(.75, 1.2), cex.lab = 1.25,
       xlabs = KBO$Permanent, xlab = "PC 1", ylab = "PC 2")
```

---
## Summary 

-  It's wiser to scale the variables before PCA, or, do PCA on the correlation matrix rather than the covariance matrix. 

-  The principal components from the covariance matrix simply reflect the order of the sizes of the variances of the observed
variables.

---
class: inverse, center, middle

## Other issues! 

---
## How many components?

-  If you have $p$ variables in your data, then taking all the $p$ principal components will explain 100% variability in your data. 

-  The usefulness of PC stems from the idea that often the first few PCs explain most of the variability in the data. 

-  There are informal and formal methods for the choice of number of components. We will cover just a few popular methods, all of which are more or less *ad-hoc* in nature! 


---
## Method 1 (Proportion of total variance)

-   Retain just enough components to explain some specified large percentage of the total variation of the original variables. 

-  Values between 70% and 90% are usually suggested, although smaller values might be appropriate as $p$ or $n$, the sample size, increases.

---
## Method 2 (Kaiser's rule)

-  $\lambda > 1$, or average eigenvalue. 

-   When the components are extracted from the covariance matrix $\mathbf{S}$: exclude those principal components whose eigenvalues are less than the average $\sum_{i=1}^{p} \lambda_i/p$. 

-  Why? Since the sum of the eigenvalues is same as the sum of variances, i.e. $\sum_{i=1}^{p} \lambda_i = \sum_{i=1}^{p} {\rm var}(X_i)$. 

-  Intuition: keep those PCs that account for more variance than the average for the observed variables.

---
## Method 2 (Kaiser's rule, contd.)


-  When the components are extracted from the correlation matrix,
$trace(R) = p$ = the number of variables, and the average variance is therefore $trace(R)/p = 1$. 

-  Applying the rule in the previous slide, components with eigenvalues less than one are excluded.

-  This rule was originally suggested by Kaiser (1958), but Jolliffe (1972), on the basis of a number of simulation studies, proposed that a more appropriate procedure would be to exclude components extracted from a correlation matrix whose associated eigenvalues are less than $0.7$.

-  You can also apply bootstrap on Kaiser's method for estimating variance, but I'll skip that. 

---
## Method 3. Scree diagram

-  Cattell (1966) suggests examination of the plot of the $\lambda_i$ against $i$, the so-called scree diagram. 

-  The number of components selected is the value of $i$
corresponding to an "elbow" in the curve, i.e., a change of slope from "steep" to "shallow". 

-  In fact, Cattell was more specific than this, recommending
to look for a point on the plot beyond which the scree diagram defines a more or less straight line, not necessarily horizontal.

---
## Scree diagram 

```{r, fig.asp = 0.8, fig.align = 'center'}
pca_crime <- princomp(crime, cor = TRUE)
screeplot(pca_crime, col = "red", pch = 16,
type = "lines", cex = 2, lwd = 2, main = "")
```





---
## Method 4: log-eigenvalue plot 

- Farmer (1971) proposed a modification: the log-
eigenvalue diagram consisting of a plot of $\log(\lambda_i)$ against $i$.


```{r, fig.asp = 0.7, fig.align = 'center'}
plot(log(pca_crime$sdev^2), xlab = "Component number", 
     ylab = "log(Component variance)", type="p",
     main = "Log(eigenvalue) diagram", col = "red", pch = 16)
lines(log(pca_crime$sdev^2),col = "red")
```

---
## Method 5: Broken stick! 

-   Broken stick model
-   Specifies model for eigenvalues under randomness,
eigenvalue is interpretable if it exceeds the model value $\lambda_k > b_k$.


$$
\begin{equation}
b_k = \sum_{i = k}^{p} \frac{1}{i}.
\end{equation}
$$

-  `R` codes here: [https://en.proft.me/2016/11/15/principal-component-analysis-pca-r/](https://en.proft.me/2016/11/15/principal-component-analysis-pca-r/).

---
## Broken stick 

```{r, echo = F, fig.align = 'center'}
ev = pca_crime$sdev^2
evplot = function(ev) {
  # Broken stick model (MacArthur 1957)
  n = length(ev)
  bsm = data.frame(j=seq(1:n), p=0)
  bsm$p[1] = 1/n
  for (i in 2:n) bsm$p[i] = bsm$p[i-1] + (1/(n + 1 - i))
  bsm$p = 100*bsm$p/n
  # Plot eigenvalues and % of variation for each axis
  op = par(mfrow=c(1,2), omi=c(0.1,0.3,0.1,0.1), mar=c(1, 1, 1, 1))
  barplot(ev, main="Eigenvalues", col="deeppink4", las=2)
  abline(h=mean(ev), col="darkorange")
  legend("topright", "Average eigenvalue", lwd=1, col=2, bty="n")
  barplot(t(cbind(100*ev/sum(ev), bsm$p[n:1])), beside=TRUE, 
          main="% variation", col=c("deeppink4",2), las=2)
  legend("topright", c("% eigenvalue", "Broken stick model"), 
         pch=15, col=c("deeppink4",2), bty="n")
  par(op)
}

evplot(ev)
```



---
##  Best?

-  Jackson (1993), Peres-Neto et al. (2005) compared various methods
-   favors the broken stick model approach or bootstrap
approach
-   scree plot tends to overestimate (by one) the number of
components
-   eigenvalues >1 overestimates number

>  No globally best method! 

>  Best to try to evaluate validity of smaller components.
