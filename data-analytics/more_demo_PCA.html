<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>More on PCA</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jyotishka Datta" />
    <meta name="date" content="2025-02-17" />
    <script src="more_demo_PCA_files/header-attrs/header-attrs.js"></script>
    <link href="more_demo_PCA_files/remark-css/default.css" rel="stylesheet" />
    <link href="more_demo_PCA_files/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="more_demo_PCA_files/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="more_demo_PCA_files/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# More on PCA
]
.author[
### Jyotishka Datta
]
.date[
### 2025-02-17
]

---




## Source/Reading:

-  These slides have `R` codes and commentary and in addition the following sections are heavily recommended: 

&gt;  Chapter 8.1 - 8.4 from Zelterman's book.


&gt;  Chapter 3.1 - 3.12 from Everitt's book. 


---
## Example: Pluto (Zelterman)

-  In 2006, Pluto was demoted from the status of a planet and is now considered one of the many objects orbitting the sun at a similar distance. 

- KBO: Kuiper belt objects: more than a thousand known objects, and there are estimates of many tens of thousands more yet to be discovered.

&lt;img src="images/Kuiperbelt.jpg" width="600" height="300" /&gt;



---
## Example: Pluto 

-  Data from the largest KBO's below. 
-  `Albedo`: light reflected rather than absorbed. 
-  `Absolute magnitude`: Apparent brightness, corrected for distance in log-scale. 
-   Is Pluto similar to the other KBOs?

&lt;img src="images/pluto.png" width="600" height="300" /&gt;


---
## Kuiper Belt Object 


``` r
KBO &lt;- read.csv("kuiper_belt_objects.csv")
str(KBO)
```

```
## 'data.frame':	13 obs. of  7 variables:
##  $ Permanent               : chr  "Pluto" "Makemake" "Haumea" "Charon" ...
##  $ Provisional             : chr  "" "2005 FY9" "2003 EL61" "S/1978 P 1" ...
##  $ Absolute.magnitude      : num  -1 -0.3 0.1 1 2.3 2.6 3.2 3.3 3.3 3.6 ...
##  $ Albedo....              : num  60 80 84 40 19.7 19.9 12 10 11.7 11.5 ...
##  $ Equatorial.diameter..km.: num  2320 1500 1150 1205 946 ...
##  $ Semi.major.axis..AU.    : num  39.4 45.7 43.3 39.4 39.4 43.5 39.6 43.1 47.4 42.5 ...
##  $ Year.of.discovery       : int  1930 2005 2005 1978 2004 2002 2001 2002 2002 2002 ...
```

``` r
Kuiper &lt;- KBO[,-c(1,2)]
colnames(Kuiper) &lt;- c("mag","albedo","diameter","axis","year")
head(Kuiper, n = 3)
```

```
##    mag albedo diameter axis year
## 1 -1.0     60     2320 39.4 1930
## 2 -0.3     80     1500 45.7 2005
## 3  0.1     84     1150 43.3 2005
```

---
## Principal Components

-  Perform PCA on the `Kuiper` dataset. 


``` r
KuiPC &lt;- princomp(Kuiper)
summary(KuiPC)
```

```
## Importance of components:
##                             Comp.1       Comp.2       Comp.3       Comp.4
## Standard deviation     467.8572498 20.201186318 7.1607984150 2.139462e+00
## Proportion of Variance   0.9978846  0.001860404 0.0002337634 2.086714e-05
## Cumulative Proportion    0.9978846  0.999745036 0.9999787991 9.999997e-01
##                              Comp.5
## Standard deviation     2.705783e-01
## Proportion of Variance 3.337641e-07
## Cumulative Proportion  1.000000e+00
```

- From this,we see 99.8% of the variability is explained in the first principal component.
On the surface, this appears to be a remarkable reduction in the dimensionality
of the problem.

---
## Loadings

-  The first PC is simply the diameter variable. Why is that? 


``` r
KuiPC$loadings
```

```
## 
## Loadings:
##          Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## mag                                   0.999
## albedo          -0.876 -0.480              
## diameter -0.999                            
## axis                           0.995       
## year            -0.478  0.872              
## 
##                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## SS loadings       1.0    1.0    1.0    1.0    1.0
## Proportion Var    0.2    0.2    0.2    0.2    0.2
## Cumulative Var    0.2    0.4    0.6    0.8    1.0
```

---
## Look at the variances 

-  This happens because the variances (or the standard deviations) of the variables are widely different.

-  The `diameter` variable has the largest variability, by far. Hence it dominates the first PC. 


``` r
sapply(Kuiper, sd)
```

```
##        mag     albedo   diameter       axis       year 
##   1.720651  27.385416 486.254960   2.595953  20.746331
```


---
## PCA on Correlation matrix

-  A better approach, then, is to record all of these values on the same scale. The principal components should be obtained from the correlation matrix in most cases.

-   use the `cor=TRUE` option as in this dialog:



``` r
KuiPCc &lt;- princomp(Kuiper, cor = TRUE)

summary(KuiPCc)
```

```
## Importance of components:
##                          Comp.1    Comp.2     Comp.3      Comp.4      Comp.5
## Standard deviation     1.786893 1.1359476 0.67202742 0.219707937 0.129404878
## Proportion of Variance 0.638597 0.2580754 0.09032417 0.009654316 0.003349125
## Cumulative Proportion  0.638597 0.8966724 0.98699656 0.996650875 1.000000000
```

-  The first two principal components account for almost 90% of the variability.

---
## New Loadings


``` r
KuiPCc$loadings
```

```
## 
## Loadings:
##          Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## mag       0.538  0.194  0.188  0.161  0.782
## albedo   -0.463 -0.405 -0.446  0.493  0.424
## diameter -0.546         0.216 -0.671  0.451
## axis      0.109 -0.785  0.608              
## year      0.432 -0.424 -0.591 -0.529       
## 
##                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5
## SS loadings       1.0    1.0    1.0    1.0    1.0
## Proportion Var    0.2    0.2    0.2    0.2    0.2
## Cumulative Var    0.2    0.4    0.6    0.8    1.0
```

The first principal component of the Kuiper objects is approximately
$$
{\rm Magnitude + Year~of~discovery - Albedo - Diameter}
$$

and the second component is almost entirely the axis.

---
## Biplot


``` r
biplot(KuiPCc, col = c(2,3), cex = c(.75, 1.2), cex.lab = 1.25,
       xlabs = KBO$Permanent, xlab = "First principal component", ylab = "Second principal component")
```

&lt;img src="more_demo_PCA_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---
## Summary 

-  It's wiser to scale the variables before PCA, or, do PCA on the correlation matrix rather than the covariance matrix. 

-  The principal components from the covariance matrix simply reflect the order of the sizes of the variances of the observed
variables.

---
class: inverse, center, middle

## Other issues! 

---
## How many components?

-  If you have `\(p\)` variables in your data, then taking all the `\(p\)` principal components will explain 100% variability in your data. 

-  The usefulness of PC stems from the idea that often the first few PCs explain most of the variability in the data. 

-  There are informal and formal methods for the choice of number of components. We will cover just a few popular methods, all of which are more or less *ad-hoc* in nature! 


---
## Method 1 (Proportion of total variance)

-   Retain just enough components to explain some specified large percentage of the total variation of the original variables. 

-  Values between 70% and 90% are usually suggested, although smaller values might be appropriate as `\(p\)` or `\(n\)`, the sample size, increases.

---
## Method 2 (Kaiser's rule)

-  `\(\lambda &gt; 1\)`, or average eigenvalue. 

-   When the components are extracted from the covariance matrix `\(\mathbf{S}\)`: exclude those principal components whose eigenvalues are less than the average `\(\sum_{i=1}^{p} \lambda_i/p\)`. 

-  Why? Since the sum of the eigenvalues is same as the sum of variances, i.e. `\(\sum_{i=1}^{p} \lambda_i = \sum_{i=1}^{p} {\rm var}(X_i)\)`. 

-  Intuition: keep those PCs that account for more variance than the average for the observed variables.

---
## Method 2 (Kaiser's rule, contd.)


-  When the components are extracted from the correlation matrix,
`\(trace(R) = p\)` = the number of variables, and the average variance is therefore `\(trace(R)/p = 1\)`. 

-  Applying the rule in the previous slide, components with eigenvalues less than one are excluded.

-  This rule was originally suggested by Kaiser (1958), but Jolliffe (1972), on the basis of a number of simulation studies, proposed that a more appropriate procedure would be to exclude components extracted from a correlation matrix whose associated eigenvalues are less than `\(0.7\)`.

-  You can also apply bootstrap on Kaiser's method for estimating variance, but I'll skip that. 

---
## Method 3. Scree diagram

-  Cattell (1966) suggests examination of the plot of the `\(\lambda_i\)` against `\(i\)`, the so-called scree diagram. 

-  The number of components selected is the value of `\(i\)`
corresponding to an "elbow" in the curve, i.e., a change of slope from "steep" to "shallow". 

-  In fact, Cattell was more specific than this, recommending
to look for a point on the plot beyond which the scree diagram defines a more or less straight line, not necessarily horizontal.

---
## Scree diagram 


``` r
crime&lt;-read.table("~/GitHub/DattaHub.github.io/data-analytics/data/city_crime.txt")
screeplot(princomp(crime, cor = TRUE), col = "red", pch = 16,
type = "lines", cex = 2, lwd = 2, main = "")
```

&lt;img src="more_demo_PCA_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;





---
## Method 4: log-eigenvalue plot 

- Farmer (1971) proposed a modification: the log-
eigenvalue diagram consisting of a plot of `\(\log(\lambda_i)\)` against `\(i\)`.



``` r
pca_crime &lt;- princomp(crime, cor = TRUE)
plot(log(pca_crime$sdev^2), xlab = "Component number", ylab = "log(Component variance)", type="p", main = "Log(eigenvalue) diagram", col = "red", pch = 16)
lines(log(pca_crime$sdev^2),col = "red")
```

&lt;img src="more_demo_PCA_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---
## Method 5: Broken stick! 

-   Broken stick model
-   Specifies model for eigenvalues under randomness,
eigenvalue is interpretable if it exceeds the model value `\(\lambda_k &gt; b_k\)`.


$$
`\begin{equation}
b_k = \sum_{i = k}^{p} \frac{1}{i}.
\end{equation}`
$$

-  `R` codes here: [https://en.proft.me/2016/11/15/principal-component-analysis-pca-r/](https://en.proft.me/2016/11/15/principal-component-analysis-pca-r/).

---
## Broken stick 

&lt;img src="more_demo_PCA_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;



---
##  Best?

-  Jackson (1993), Peres-Neto et al. (2005) compared various methods
-   favors the broken stick model approach or bootstrap
approach
-   scree plot tends to overestimate (by one) the number of
components
-   eigenvalues &gt;1 overestimates number

&gt;  No globally best method! 

&gt;  Best to try to evaluate validity of smaller components.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
